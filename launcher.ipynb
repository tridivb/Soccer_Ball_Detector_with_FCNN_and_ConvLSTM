{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab CudaVision (MA-INF 4308)\n",
    "\n",
    "## Submission by: Tridivraj Bhattacharyya (3035538)\n",
    "\n",
    "### Dependencies:\n",
    "1. Python 3.6\n",
    "2. Pytorch 0.4.1\n",
    "3. Torchvision\n",
    "4. Visdom\n",
    "5. Numpy\n",
    "6. ImageIo\n",
    "7. OpenCV 3.x\n",
    "8. Pandas\n",
    "9. PIL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usable Paramters to initialize the code:\n",
    "*select model type - 1 (SweatyNet1) | 2 (SweatyNet2) | 3 (SweatyNet3) (Default: 3)'* <br>\n",
    "``model = 2`` <br> <br>\n",
    "*training set annotations and file names* <br>\n",
    "``traincsv = './data/imageset_train_annotations.csv'`` <br> <br>\n",
    "*path to training set files* <br>\n",
    "``trainset = './data/train'`` <br> <br>\n",
    "*size of training batch* <br> \n",
    "``train_batch_size = 4`` <br> <br>\n",
    "*test set annotations and file names* <br>\n",
    "``testcsv = './data/imageset_test_annotations.csv'`` <br> <br>\n",
    "*path to test set files* <br>\n",
    "``testset = './data/test'`` <br> <br>\n",
    "*size of test batch* <br>\n",
    "``test_batch_size = 10`` <br> <br>\n",
    "*checkpoint file to load* <br>\n",
    "``checkpoint = None`` <br> <br>\n",
    "*no of workers to load dataset* <br>\n",
    "``workers = 2`` <br> <br>\n",
    "*no of iterations* <br>\n",
    "``niter = 25`` <br> <br>\n",
    "*learning rate* <br>\n",
    "``lr = 0.001`` <br> <br>\n",
    "*momentum for adam optimizer* <br>\n",
    "``beta1 = 0.9`` <br> <br>\n",
    "*path to output checkpoint and data* <br>\n",
    "``outpath = './output'`` <br> <br>\n",
    "*manual seed for randomizer* <br>\n",
    "``manual_seed = 42`` <br> <br>\n",
    "*the height of the input image to network* <br>\n",
    "``image_height = 512`` <br> <br>\n",
    "*the width of the input image to network* <br>\n",
    "``image_width = 640`` <br> <br>\n",
    "*Input video file to process. Training will be turned off.* <br>\n",
    "``input_vid = None`` <br> <br>\n",
    "\n",
    "\n",
    "*To use the following flags just pass them as arguments while calling main.py <br>\n",
    "eg. To turn off training use ``python main.py --train_off``* <br> <br>\n",
    "*Freeze weights of SweatyNet (Default: False)* <br>\n",
    "``freeze_wts = False`` <br> <br>\n",
    "*Add ConvLSTM to model (Default: False)* <br>\n",
    "``use_ConvLSTM = False`` <br> <br>\n",
    "*Turn off training (Default: False)* <br>\n",
    "``train_off = False``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions: The main.py initializes the models and starts the training. Available parameters along with their descriptions and default values are provided above. To freeze weights include --freeze_wts flag. Similary to include Convolutional LSTM to model, add --use_ConvLSTM flag.**\n",
    "\n",
    "**Please start the visdom server separately using ``python -m visdom.server``. Starting it in jupyter might slow down the notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(beta1=0.9, checkpoint=None, freeze_wts=False, image_height=512, image_width=640, input_vid=None, lr=0.001, manual_seed=42, model=1, niter=1, outpath='./output', test_batch_size=10, testcsv='./data/imageset_test_annotations.csv', testset='./data/test', train_batch_size=4, train_off=False, traincsv='./data/imageset_train_annotations.csv', trainset='./data/train', use_ConvLSTM=False, workers=2)\n",
      "=============================================================\n",
      "./output/checkpoint already exists.\n",
      "=============================================================\n",
      "./output/media already exists.\n",
      "=============================================================\n",
      "Model: SweatyNet1 selected.\n",
      "=============================================================\n",
      "Model Initialized. Start Epoch: 0, Min Validation Loss: inf\n",
      "=============================================================\n",
      "Training in progress...\n",
      "-------------------------------------------------------------\n",
      "Train Epoch: 1 [0/2900 (0%)]\tLoss: 4924.100586\n",
      "Train Epoch: 1 [900/2900 (31%)]\tLoss: 19.820124\n",
      "Train Epoch: 1 [1800/2900 (62%)]\tLoss: 2.825253\n",
      "Train Epoch: 1 [2700/2900 (93%)]\tLoss: 8.813757\n",
      "Epoch: 1, Train Loss: 42.865596771240234, Validation Loss: 6.435216346289963e-05, Validation Recall: 96.48%, Validation FDR: 9.73%, Epoch Run Time: 2 minute(s) and 29 second(s)\n",
      "=============================================================\n",
      "Processing test data...\n",
      "-------------------------------------------------------------\n",
      "Test Loss: 7.68202735343948e-05, Testset Recall: 95.93%, Testset FDR: 2.68%\n",
      "=============================================================\n",
      "Total time taken: 0 hour(s), 3 minute(s) and 3 second(s)\n"
     ]
    }
   ],
   "source": [
    "# Example Usage:\n",
    "# Train without ConvLSTM\n",
    "# python main.py --model 1 --niter 25\n",
    "# Transfer learning and train with ConvLSTM\n",
    "# python main.py --model 1 --niter 25 --checkpoint <checkpoint_file> --use_ConvLSTM --freeze_wts\n",
    "# To only test the model\n",
    "# python main.py --model 1 --checkpoint <checkpoint_file> --use_ConvLSTM --freeze_wts --train_off\n",
    "# To process video file\n",
    "# python main.py --model 1 --checkpoint <checkpoint_file> --use_ConvLSTM --freeze_wts --input_vid <video file>\n",
    "\n",
    "!python main.py --model 1 --niter 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
